{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2d286f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bc191b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "def get_device():\n",
    "    \"\"\"Get the device to use for training.\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\")\n",
    "    elif torch.backends.mps.is_available():\n",
    "        return torch.device(\"mps\")\n",
    "    else:\n",
    "        return torch.device(\"cpu\")\n",
    "    \n",
    "print(f\"Using device: {get_device()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81056cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MRIDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        image = Image.open(image_path)\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9402e1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_oasis_data(data_dir=\"../OasisImages\"):\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "    label_names = []\n",
    "\n",
    "    class_dirs = sorted([d for d in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, d))])\n",
    "\n",
    "    print(f\"Found {len(class_dirs)} classes: {class_dirs}\")\n",
    "\n",
    "    for class_idx, class_name in enumerate(class_dirs):\n",
    "        class_path = os.path.join(data_dir, class_name)\n",
    "        label_names.append(class_name)\n",
    "\n",
    "        class_images = []\n",
    "        for img_file in os.listdir(class_path):\n",
    "            if img_file.lower().endswith((\".jpg\")):\n",
    "                image_paths.append(os.path.join(class_path, img_file))\n",
    "                labels.append(class_idx)\n",
    "                class_images.append(img_file)\n",
    "\n",
    "        print(f\"Class '{class_name}' (label {class_idx}): {len(class_images)} images\")\n",
    "\n",
    "    print(f\"Total images loaded: {len(image_paths)}\")\n",
    "    return image_paths, labels, label_names\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20343c0e",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e13739d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OasisModel(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super(OasisModel, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "        # Adjust based on input size (224x224 -> 14x14 after 4 pooling layers)\n",
    "        self.fc1 = nn.Linear(256 * 14 * 14, 512)\n",
    "        self.fc2 = nn.Linear(512, 128)\n",
    "        self.fc3 = nn.Linear(128, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = self.pool(F.relu(self.conv4(x)))\n",
    "        \n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbe49673",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transforms():\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(p=0.3),\n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    return train_transform, val_transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d10242d",
   "metadata": {},
   "source": [
    "# Training & Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e9b6d48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, criterion, device, epoch, num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total_samples = 0 + 1e-8\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        \n",
    "        if batch_idx == 0:\n",
    "            print(f'Epoch: {epoch}/{num_epochs}, Batch: {batch_idx}, ' f'Loss: {loss.item():.6f}, Accuracy: {100.*total_correct/total_samples:.2f}')\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_accuracy = 100. * total_correct / total_samples\n",
    "    return epoch_loss, epoch_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e7861bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, val_loader, criterion, deivce):\n",
    "    model.eval()\n",
    "    validation_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in val_loader:\n",
    "            data, target = data.to(deivce), target.to(deivce)\n",
    "            output = model(data)\n",
    "            validation_loss += criterion(output, target).item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            total_correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            total_samples += target.size(0)\n",
    "\n",
    "    validation_loss /= len(val_loader)\n",
    "    validation_accuracy = 100. * total_correct / total_samples\n",
    "    return validation_loss, validation_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9eb665b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_oasis_model():\n",
    "    batch_size = 32\n",
    "    num_epochs = 10\n",
    "    learning_rate = 0.001\n",
    "    device = get_device()\n",
    "\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # Load data\n",
    "    image_paths, labels, label_names = load_oasis_data()\n",
    "\n",
    "    # Split data into training and validation sets\n",
    "    train_paths, val_paths, train_labels, val_labels = train_test_split(\n",
    "        image_paths, labels, test_size=0.2, random_state=42, stratify=labels\n",
    "    )\n",
    "\n",
    "    print(f\"Training samples: {len(train_paths)}\")\n",
    "    print(f\"Validation samples: {len(val_paths)}\")\n",
    "\n",
    "    train_transform, val_transform = get_transforms()\n",
    "\n",
    "    train_dataset = MRIDataset(train_paths, train_labels, transform=train_transform)\n",
    "    validation_dataset = MRIDataset(val_paths, val_labels, transform=val_transform)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    model = OasisModel().to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "    best_val_accuracy = 0.0\n",
    "    train_losses, val_losses = [], []\n",
    "    train_accuracies, val_accuracies = [], []\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        train_loss, train_accuracy = train(model, train_loader, optimizer, criterion, device, epoch, num_epochs)\n",
    "        validation_loss, validation_accuracy = validate(model, val_loader, criterion, device)\n",
    "\n",
    "        scheduler.step()\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(validation_loss)\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        val_accuracies.append(validation_accuracy)\n",
    "\n",
    "        print(f'Epoch {epoch}: Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.2f}%, '\n",
    "              f'Val Loss: {validation_loss:.4f}, Val Acc: {validation_accuracy:.2f}%')\n",
    "        \n",
    "        if validation_accuracy > best_val_accuracy:\n",
    "            best_val_accuracy = validation_accuracy\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'best_val_accuracy': best_val_accuracy,\n",
    "                'label_names': label_names\n",
    "            }, f'best_oasis_model.pth')\n",
    "            print(f'Best Validation Accuracy: {best_val_accuracy:.2f}%')\n",
    "\n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'label_names': label_names\n",
    "    }, f\"final_oasis_model.pth\")\n",
    "\n",
    "    return model, label_names\n",
    "\n",
    "\n",
    "\n",
    "model, label_names = train_oasis_model()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902480af",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245d9ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Model on Random Samples using saved model\n",
    "import random\n",
    "\n",
    "def load_saved_model(model_path='best_oasis_model.pth'):\n",
    "    \"\"\"Load the saved model from file\"\"\"\n",
    "    device = get_device()\n",
    "    \n",
    "    # Load the checkpoint\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    \n",
    "    # Get label names and number of classes\n",
    "    label_names = checkpoint['label_names']\n",
    "    num_classes = len(label_names)\n",
    "    \n",
    "    # Initialize model\n",
    "    model = OasisModel(num_classes=num_classes)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    print(f\"Model loaded from {model_path}\")\n",
    "    print(f\"Best validation accuracy: {checkpoint['best_val_accuracy']:.2f}%\")\n",
    "    print(f\"Classes: {label_names}\")\n",
    "    \n",
    "    return model, label_names\n",
    "\n",
    "def test_model_random_samples(model, label_names, num_samples=10):\n",
    "    \"\"\"Test model on random samples and print confidence scores\"\"\"\n",
    "    device = get_device()\n",
    "    model.eval()\n",
    "    \n",
    "    # Load data and get validation transform\n",
    "    image_paths, labels, _ = load_oasis_data()\n",
    "    _, val_transform = get_transforms()\n",
    "    \n",
    "    # Randomly select samples\n",
    "    random_indices = random.sample(range(len(image_paths)), num_samples)\n",
    "    \n",
    "    print(f\"\\nTesting model on {num_samples} random samples:\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    correct_predictions = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, idx in enumerate(random_indices):\n",
    "            # Load and preprocess image\n",
    "            image_path = image_paths[idx]\n",
    "            true_label = labels[idx]\n",
    "            \n",
    "            image = Image.open(image_path).convert('RGB')\n",
    "            image_tensor = val_transform(image).unsqueeze(0).to(device)\n",
    "            \n",
    "            # Get model prediction\n",
    "            output = model(image_tensor)\n",
    "            probabilities = F.softmax(output, dim=1)\n",
    "            confidence_scores = probabilities.cpu().numpy()[0]\n",
    "            \n",
    "            predicted_class = torch.argmax(output, dim=1).item()\n",
    "            max_confidence = confidence_scores[predicted_class]\n",
    "            \n",
    "            # Check if prediction is correct\n",
    "            is_correct = predicted_class == true_label\n",
    "            if is_correct:\n",
    "                correct_predictions += 1\n",
    "            \n",
    "            print(f\"Sample {i+1}:\")\n",
    "            print(f\"  Image: {os.path.basename(image_path)}\")\n",
    "            print(f\"  True Label: {label_names[true_label]} (index {true_label})\")\n",
    "            print(f\"  Predicted: {label_names[predicted_class]} (index {predicted_class})\")\n",
    "            print(f\"  Confidence: {max_confidence:.4f} ({max_confidence*100:.2f}%)\")\n",
    "            print(f\"  Correct: {'✓' if is_correct else '✗'}\")\n",
    "            \n",
    "            # Print all class probabilities\n",
    "            print(f\"  All class probabilities:\")\n",
    "            for j, class_name in enumerate(label_names):\n",
    "                print(f\"    {class_name}: {confidence_scores[j]:.4f} ({confidence_scores[j]*100:.2f}%)\")\n",
    "            print(\"-\" * 60)\n",
    "    \n",
    "    accuracy = correct_predictions / num_samples\n",
    "    print(f\"\\nTest Results:\")\n",
    "    print(f\"Accuracy: {correct_predictions}/{num_samples} = {accuracy:.2f} ({accuracy*100:.1f}%)\")\n",
    "\n",
    "# Load the saved model and run tests\n",
    "model, label_names = load_saved_model('best_oasis_model.pth')\n",
    "test_model_random_samples(model, label_names, num_samples=86000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "integrated-gradients",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
